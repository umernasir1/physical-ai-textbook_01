"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[3361],{6271:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>p,frontMatter:()=>t,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"module1-ros2/python-agents-and-rclpy","title":"Bridging Python Agents to ROS Controllers using rclpy","description":"Introduction","source":"@site/docs/module1-ros2/python-agents-and-rclpy.md","sourceDirName":"module1-ros2","slug":"/module1-ros2/python-agents-and-rclpy","permalink":"/physical-ai-textbook_01/docs/module1-ros2/python-agents-and-rclpy","draft":false,"unlisted":false,"editUrl":"https://github.com/umernasir1/physical-ai-textbook/tree/main/docs/module1-ros2/python-agents-and-rclpy.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Bridging Python Agents to ROS Controllers using rclpy"},"sidebar":"tutorialSidebar","previous":{"title":"ROS 2 Nodes, Topics, and Services","permalink":"/physical-ai-textbook_01/docs/module1-ros2/ros2-nodes-topics-services"},"next":{"title":"Understanding URDF for Humanoids","permalink":"/physical-ai-textbook_01/docs/module1-ros2/urdf-for-humanoids"}}');var i=r(4848),o=r(8453);const t={sidebar_position:3,title:"Bridging Python Agents to ROS Controllers using rclpy"},l="Bridging Python Agents to ROS Controllers using rclpy",a={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Why Python for Robotics?",id:"why-python-for-robotics",level:2},{value:"Setting Up rclpy",id:"setting-up-rclpy",level:2},{value:"Installation",id:"installation",level:3},{value:"Creating a Workspace",id:"creating-a-workspace",level:3},{value:"Building Your First AI-Enabled ROS 2 Node",id:"building-your-first-ai-enabled-ros-2-node",level:2},{value:"Example: AI Decision Node",id:"example-ai-decision-node",level:3},{value:"Key Components Explained",id:"key-components-explained",level:3},{value:"Integrating Deep Learning Models",id:"integrating-deep-learning-models",level:2},{value:"Example: Vision-Based Object Detection",id:"example-vision-based-object-detection",level:3},{value:"Services for AI Inference",id:"services-for-ai-inference",level:2},{value:"Creating an AI Inference Service",id:"creating-an-ai-inference-service",level:3},{value:"Calling the Service from a Client",id:"calling-the-service-from-a-client",level:3},{value:"Best Practices for AI-ROS Integration",id:"best-practices-for-ai-ros-integration",level:2},{value:"1. Separate Computation from Communication",id:"1-separate-computation-from-communication",level:3},{value:"2. Handle Timing Constraints",id:"2-handle-timing-constraints",level:3},{value:"3. Optimize Performance",id:"3-optimize-performance",level:3},{value:"4. Error Handling",id:"4-error-handling",level:3},{value:"Real-World Example: Humanoid Grasping with AI",id:"real-world-example-humanoid-grasping-with-ai",level:2},{value:"Conclusion",id:"conclusion",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"bridging-python-agents-to-ros-controllers-using-rclpy",children:"Bridging Python Agents to ROS Controllers using rclpy"})}),"\n",(0,i.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,i.jsxs)(n.p,{children:["In the age of AI-powered robotics, the ability to bridge intelligent software agents with physical robot controllers is essential. ROS 2 provides ",(0,i.jsx)(n.code,{children:"rclpy"}),"\u2014a Python client library that enables seamless integration between AI models (like those built with TensorFlow, PyTorch, or OpenAI APIs) and robotic hardware."]}),"\n",(0,i.jsx)(n.p,{children:"This chapter covers how to:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Set up ",(0,i.jsx)(n.code,{children:"rclpy"})," for Python-based ROS 2 development"]}),"\n",(0,i.jsx)(n.li,{children:"Create nodes that integrate AI decision-making with robot control"}),"\n",(0,i.jsx)(n.li,{children:"Design publisher-subscriber patterns for AI-robot communication"}),"\n",(0,i.jsx)(n.li,{children:"Implement service-based AI inference for robotics"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"why-python-for-robotics",children:"Why Python for Robotics?"}),"\n",(0,i.jsx)(n.p,{children:"Python has become the lingua franca of AI and machine learning:"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Advantages:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Rich ecosystem of AI/ML libraries (TensorFlow, PyTorch, scikit-learn)"}),"\n",(0,i.jsx)(n.li,{children:"Rapid prototyping and development"}),"\n",(0,i.jsx)(n.li,{children:"Easy integration with cloud APIs (OpenAI, Google Cloud AI)"}),"\n",(0,i.jsx)(n.li,{children:"Extensive data processing tools (NumPy, Pandas)"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Challenges:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Performance limitations compared to C++"}),"\n",(0,i.jsx)(n.li,{children:"Global Interpreter Lock (GIL) restricts multithreading"}),"\n",(0,i.jsx)(n.li,{children:"Not suitable for real-time critical control loops"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Best Practice:"})," Use Python for high-level planning and AI inference, C++ for low-level motor control and sensor processing."]}),"\n",(0,i.jsx)(n.h2,{id:"setting-up-rclpy",children:"Setting Up rclpy"}),"\n",(0,i.jsx)(n.h3,{id:"installation",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Install ROS 2 (Ubuntu 22.04 - Humble)\nsudo apt update\nsudo apt install ros-humble-desktop python3-colcon-common-extensions\n\n# Source ROS 2\necho "source /opt/ros/humble/setup.bash" >> ~/.bashrc\nsource ~/.bashrc\n\n# Verify installation\npython3 -c "import rclpy; print(\'rclpy ready!\')"\n'})}),"\n",(0,i.jsx)(n.h3,{id:"creating-a-workspace",children:"Creating a Workspace"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"mkdir -p ~/ros2_ws/src\ncd ~/ros2_ws\ncolcon build\nsource install/setup.bash\n"})}),"\n",(0,i.jsx)(n.h2,{id:"building-your-first-ai-enabled-ros-2-node",children:"Building Your First AI-Enabled ROS 2 Node"}),"\n",(0,i.jsx)(n.h3,{id:"example-ai-decision-node",children:"Example: AI Decision Node"}),"\n",(0,i.jsx)(n.p,{children:"Let's create a node that uses AI to make navigation decisions based on sensor data."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist\nfrom sensor_msgs.msg import LaserScan\nimport numpy as np\n\nclass AINavigationNode(Node):\n    def __init__(self):\n        super().__init__('ai_navigation_node')\n\n        # Create publisher for robot velocity commands\n        self.velocity_publisher = self.create_publisher(\n            Twist,\n            '/cmd_vel',\n            10\n        )\n\n        # Create subscriber for laser scan data\n        self.laser_subscriber = self.create_subscription(\n            LaserScan,\n            '/scan',\n            self.laser_callback,\n            10\n        )\n\n        self.get_logger().info('AI Navigation Node initialized')\n\n    def laser_callback(self, msg):\n        \"\"\"Process laser scan data and make navigation decisions\"\"\"\n        # Extract distances from laser scan\n        ranges = np.array(msg.ranges)\n\n        # Simple AI logic: avoid obstacles\n        front_distance = np.mean(ranges[len(ranges)//2 - 10: len(ranges)//2 + 10])\n        left_distance = np.mean(ranges[0:len(ranges)//4])\n        right_distance = np.mean(ranges[3*len(ranges)//4:])\n\n        # Create velocity command\n        cmd = Twist()\n\n        if front_distance < 0.5:  # Obstacle ahead\n            # Turn toward more open space\n            if left_distance > right_distance:\n                cmd.angular.z = 0.5  # Turn left\n            else:\n                cmd.angular.z = -0.5  # Turn right\n            cmd.linear.x = 0.0\n        else:\n            # Path is clear, move forward\n            cmd.linear.x = 0.2\n            cmd.angular.z = 0.0\n\n        # Publish command\n        self.velocity_publisher.publish(cmd)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = AINavigationNode()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,i.jsx)(n.h3,{id:"key-components-explained",children:"Key Components Explained"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"1. Node Initialization:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"super().__init__('ai_navigation_node')\n"})}),"\n",(0,i.jsx)(n.p,{children:"Every ROS 2 node needs a unique name."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"2. Publisher Creation:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"self.velocity_publisher = self.create_publisher(Twist, '/cmd_vel', 10)\n"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"Twist"}),": Message type for velocity commands"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"/cmd_vel"}),": Topic name (standard for robot velocity)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"10"}),": Queue size for message buffering"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"3. Subscriber Creation:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"self.laser_subscriber = self.create_subscription(\n    LaserScan, '/scan', self.laser_callback, 10\n)\n"})}),"\n",(0,i.jsx)(n.p,{children:"The callback function is called whenever new sensor data arrives."}),"\n",(0,i.jsx)(n.h2,{id:"integrating-deep-learning-models",children:"Integrating Deep Learning Models"}),"\n",(0,i.jsx)(n.h3,{id:"example-vision-based-object-detection",children:"Example: Vision-Based Object Detection"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge\nimport cv2\nimport torch\nfrom torchvision.models.detection import fasterrcnn_resnet50_fpn\n\nclass ObjectDetectionNode(Node):\n    def __init__(self):\n        super().__init__('object_detection_node')\n\n        # Load pretrained model\n        self.model = fasterrcnn_resnet50_fpn(pretrained=True)\n        self.model.eval()\n\n        # OpenCV bridge for ROS-OpenCV conversion\n        self.bridge = CvBridge()\n\n        # Subscribe to camera feed\n        self.image_sub = self.create_subscription(\n            Image,\n            '/camera/image_raw',\n            self.image_callback,\n            10\n        )\n\n        self.get_logger().info('Object Detection Node ready')\n\n    def image_callback(self, msg):\n        # Convert ROS Image to OpenCV format\n        cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')\n\n        # Prepare image for model\n        image_tensor = torch.from_numpy(cv_image).permute(2, 0, 1).float() / 255.0\n        image_tensor = image_tensor.unsqueeze(0)\n\n        # Run inference\n        with torch.no_grad():\n            predictions = self.model(image_tensor)\n\n        # Process detections\n        boxes = predictions[0]['boxes'].cpu().numpy()\n        labels = predictions[0]['labels'].cpu().numpy()\n        scores = predictions[0]['scores'].cpu().numpy()\n\n        # Log detected objects\n        for box, label, score in zip(boxes, labels, scores):\n            if score > 0.7:  # Confidence threshold\n                self.get_logger().info(f'Detected: Class {label}, Score: {score:.2f}')\n"})}),"\n",(0,i.jsx)(n.h2,{id:"services-for-ai-inference",children:"Services for AI Inference"}),"\n",(0,i.jsx)(n.p,{children:"For computationally expensive AI operations, use ROS 2 services instead of continuous callbacks."}),"\n",(0,i.jsx)(n.h3,{id:"creating-an-ai-inference-service",children:"Creating an AI Inference Service"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from rclpy.node import Node\nfrom example_interfaces.srv import AddTwoInts  # Replace with custom srv\nimport rclpy\n\nclass AIInferenceService(Node):\n    def __init__(self):\n        super().__init__('ai_inference_service')\n\n        self.srv = self.create_service(\n            AddTwoInts,  # Use custom service type in practice\n            'ai_inference',\n            self.inference_callback\n        )\n\n        # Load your AI model here\n        # self.model = load_model('path/to/model.pth')\n\n    def inference_callback(self, request, response):\n        # Run AI inference\n        self.get_logger().info(f'Inference request received: {request.a}, {request.b}')\n\n        # Placeholder for actual AI computation\n        response.sum = request.a + request.b\n\n        return response\n"})}),"\n",(0,i.jsx)(n.h3,{id:"calling-the-service-from-a-client",children:"Calling the Service from a Client"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom example_interfaces.srv import AddTwoInts\n\nclass AIClient(Node):\n    def __init__(self):\n        super().__init__('ai_client')\n        self.client = self.create_client(AddTwoInts, 'ai_inference')\n\n        while not self.client.wait_for_service(timeout_sec=1.0):\n            self.get_logger().info('Service not available, waiting...')\n\n        self.send_request(5, 7)\n\n    def send_request(self, a, b):\n        request = AddTwoInts.Request()\n        request.a = a\n        request.b = b\n\n        future = self.client.call_async(request)\n        future.add_done_callback(self.response_callback)\n\n    def response_callback(self, future):\n        result = future.result()\n        self.get_logger().info(f'AI Inference Result: {result.sum}')\n"})}),"\n",(0,i.jsx)(n.h2,{id:"best-practices-for-ai-ros-integration",children:"Best Practices for AI-ROS Integration"}),"\n",(0,i.jsx)(n.h3,{id:"1-separate-computation-from-communication",children:"1. Separate Computation from Communication"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Keep AI inference in separate threads/processes"}),"\n",(0,i.jsx)(n.li,{children:"Use ROS 2's executor for efficient callback management"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"2-handle-timing-constraints",children:"2. Handle Timing Constraints"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Create a timer for periodic AI updates\nself.timer = self.create_timer(0.1, self.ai_update_callback)  # 10 Hz\n"})}),"\n",(0,i.jsx)(n.h3,{id:"3-optimize-performance",children:"3. Optimize Performance"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Use ",(0,i.jsx)(n.code,{children:"torch.jit"})," or ONNX for model optimization"]}),"\n",(0,i.jsx)(n.li,{children:"Leverage GPU acceleration when available"}),"\n",(0,i.jsx)(n.li,{children:"Consider model quantization for edge deployment"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"4-error-handling",children:"4. Error Handling"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"def safe_inference(self, data):\n    try:\n        result = self.model(data)\n        return result\n    except Exception as e:\n        self.get_logger().error(f'Inference failed: {str(e)}')\n        return None\n"})}),"\n",(0,i.jsx)(n.h2,{id:"real-world-example-humanoid-grasping-with-ai",children:"Real-World Example: Humanoid Grasping with AI"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom std_msgs.msg import Float32MultiArray\n\nclass GraspingNode(Node):\n    def __init__(self):\n        super().__init__('grasping_ai_node')\n\n        # Subscribe to hand camera\n        self.camera_sub = self.create_subscription(\n            Image,\n            '/hand_camera/image',\n            self.detect_grasp_pose,\n            10\n        )\n\n        # Publish grasp commands\n        self.grasp_pub = self.create_publisher(\n            Float32MultiArray,\n            '/grasp_pose',\n            10\n        )\n\n    def detect_grasp_pose(self, msg):\n        # Run AI model to detect optimal grasp pose\n        # (Using a pretrained grasp detection network)\n\n        # Convert image\n        image = self.bridge.imgmsg_to_cv2(msg)\n\n        # Run grasp detection AI\n        grasp_poses = self.grasp_model.predict(image)\n\n        # Publish best grasp\n        if len(grasp_poses) > 0:\n            best_grasp = grasp_poses[0]  # Highest confidence\n\n            msg = Float32MultiArray()\n            msg.data = [\n                best_grasp.x, best_grasp.y, best_grasp.z,\n                best_grasp.roll, best_grasp.pitch, best_grasp.yaw\n            ]\n            self.grasp_pub.publish(msg)\n"})}),"\n",(0,i.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,i.jsxs)(n.p,{children:["Bridging Python-based AI agents with ROS 2 using ",(0,i.jsx)(n.code,{children:"rclpy"})," unlocks powerful capabilities:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Integrate state-of-the-art AI models into robotic systems"}),"\n",(0,i.jsx)(n.li,{children:"Leverage Python's rich AI ecosystem while maintaining real-time performance"}),"\n",(0,i.jsx)(n.li,{children:"Create modular, maintainable robot software architectures"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Next Steps:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Explore URDF for describing robot structures"}),"\n",(0,i.jsx)(n.li,{children:"Learn about ROS 2 actions for long-running AI tasks"}),"\n",(0,i.jsx)(n.li,{children:"Study parameter management for AI model configuration"}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>t,x:()=>l});var s=r(6540);const i={},o=s.createContext(i);function t(e){const n=s.useContext(o);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);