"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[243],{3066:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>t,contentTitle:()=>l,default:()=>m,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"module3-ai-robot-brain/isaac-ros-vslam-navigation","title":"Isaac ROS (Hardware-accelerated VSLAM and Navigation)","description":"Introduction","source":"@site/docs/module3-ai-robot-brain/isaac-ros-vslam-navigation.md","sourceDirName":"module3-ai-robot-brain","slug":"/module3-ai-robot-brain/isaac-ros-vslam-navigation","permalink":"/-physical-ai-textbook_01/docs/module3-ai-robot-brain/isaac-ros-vslam-navigation","draft":false,"unlisted":false,"editUrl":"https://github.com/umernasir1/physical-ai-textbook/tree/main/docs/module3-ai-robot-brain/isaac-ros-vslam-navigation.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Isaac ROS (Hardware-accelerated VSLAM and Navigation)"},"sidebar":"tutorialSidebar","previous":{"title":"NVIDIA Isaac Sim","permalink":"/-physical-ai-textbook_01/docs/module3-ai-robot-brain/nvidia-isaac-sim"},"next":{"title":"Nav2 (Path Planning for Bipedal Humanoid Movement)","permalink":"/-physical-ai-textbook_01/docs/module3-ai-robot-brain/nav2-path-planning"}}');var r=a(4848),i=a(8453);const o={sidebar_position:3,title:"Isaac ROS (Hardware-accelerated VSLAM and Navigation)"},l="Isaac ROS (Hardware-accelerated VSLAM and Navigation)",t={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Why Isaac ROS for Humanoid Robots?",id:"why-isaac-ros-for-humanoid-robots",level:2},{value:"Understanding Visual SLAM (VSLAM)",id:"understanding-visual-slam-vslam",level:2},{value:"The SLAM Problem",id:"the-slam-problem",level:3},{value:"Visual Odometry vs VSLAM",id:"visual-odometry-vs-vslam",level:3},{value:"Isaac ROS VSLAM Architecture",id:"isaac-ros-vslam-architecture",level:2},{value:"System Components",id:"system-components",level:3},{value:"Installation",id:"installation",level:3},{value:"Setting Up Isaac ROS VSLAM",id:"setting-up-isaac-ros-vslam",level:2},{value:"Hardware Requirements",id:"hardware-requirements",level:3},{value:"Camera Configuration",id:"camera-configuration",level:3},{value:"Launch File for VSLAM",id:"launch-file-for-vslam",level:3},{value:"Running Isaac ROS VSLAM",id:"running-isaac-ros-vslam",level:2},{value:"Basic Usage",id:"basic-usage",level:3},{value:"Monitoring VSLAM Status",id:"monitoring-vslam-status",level:3},{value:"IMU Sensor Fusion",id:"imu-sensor-fusion",level:2},{value:"Why Fuse IMU with Visual Data?",id:"why-fuse-imu-with-visual-data",level:3},{value:"IMU Integration",id:"imu-integration",level:3},{value:"Map Management",id:"map-management",level:2},{value:"Saving and Loading Maps",id:"saving-and-loading-maps",level:3},{value:"Integration with Navigation Stack",id:"integration-with-navigation-stack",level:2},{value:"Publishing Odometry for Nav2",id:"publishing-odometry-for-nav2",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"GPU Memory Management",id:"gpu-memory-management",level:3},{value:"Resolution vs Speed Trade-off",id:"resolution-vs-speed-trade-off",level:3},{value:"Feature Count Tuning",id:"feature-count-tuning",level:3},{value:"Troubleshooting Common Issues",id:"troubleshooting-common-issues",level:2},{value:"Problem: Tracking Loss",id:"problem-tracking-loss",level:3},{value:"Problem: High Drift",id:"problem-high-drift",level:3},{value:"Problem: Slow Performance",id:"problem-slow-performance",level:3},{value:"Summary",id:"summary",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"isaac-ros-hardware-accelerated-vslam-and-navigation",children:"Isaac ROS (Hardware-accelerated VSLAM and Navigation)"})}),"\n",(0,r.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Isaac ROS"})," is NVIDIA's collection of hardware-accelerated ROS 2 packages that leverage GPU computing for real-time perception and navigation. For humanoid robots navigating complex environments, Isaac ROS provides:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"VSLAM (Visual SLAM)"}),": Build maps and localize using camera input"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"GPU Acceleration"}),": 10-100x faster than CPU-only solutions"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sensor Fusion"}),": Combine visual odometry with IMU and wheel encoders"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Production-Ready"}),": Battle-tested in NVIDIA's robotics research"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["This chapter focuses on ",(0,r.jsx)(n.strong,{children:"Visual SLAM"})," - the ability for a robot to simultaneously map its environment and determine its location using only camera data."]}),"\n",(0,r.jsx)(n.h2,{id:"why-isaac-ros-for-humanoid-robots",children:"Why Isaac ROS for Humanoid Robots?"}),"\n",(0,r.jsx)(n.p,{children:"Traditional SLAM algorithms struggle with humanoid robots because:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Dynamic Motion"}),": Bipedal walking creates rapid camera movements"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Height Variation"}),": Humanoid perspective changes as it walks"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Real-Time Requirements"}),": Balance control needs immediate localization feedback"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Isaac ROS Solutions:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"GPU-accelerated feature tracking handles fast motion"}),"\n",(0,r.jsx)(n.li,{children:"Robust loop closure detects when returning to known locations"}),"\n",(0,r.jsx)(n.li,{children:"Sub-10ms latency for real-time control loops"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"understanding-visual-slam-vslam",children:"Understanding Visual SLAM (VSLAM)"}),"\n",(0,r.jsx)(n.h3,{id:"the-slam-problem",children:"The SLAM Problem"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"SLAM = Simultaneous Localization and Mapping"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Localization"}),": Where am I?"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Mapping"}),": What does the environment look like?"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simultaneous"}),": Solve both at the same time (chicken-and-egg problem)"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Why is VSLAM Hard?"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Camera measurements are noisy and ambiguous"}),"\n",(0,r.jsx)(n.li,{children:"Features can look similar (symmetry problem)"}),"\n",(0,r.jsx)(n.li,{children:"Errors accumulate over time (drift)"}),"\n",(0,r.jsx)(n.li,{children:"Must run in real-time on limited hardware"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"visual-odometry-vs-vslam",children:"Visual Odometry vs VSLAM"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Feature"}),(0,r.jsx)(n.th,{children:"Visual Odometry"}),(0,r.jsx)(n.th,{children:"VSLAM"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Mapping"})}),(0,r.jsx)(n.td,{children:"No global map"}),(0,r.jsx)(n.td,{children:"Builds persistent map"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Loop Closure"})}),(0,r.jsx)(n.td,{children:"No"}),(0,r.jsx)(n.td,{children:"Yes (corrects drift)"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Relocalization"})}),(0,r.jsx)(n.td,{children:"Cannot recover if lost"}),(0,r.jsx)(n.td,{children:"Can relocalize in known areas"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Computational Cost"})}),(0,r.jsx)(n.td,{children:"Lower"}),(0,r.jsx)(n.td,{children:"Higher"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Accuracy"})}),(0,r.jsx)(n.td,{children:"Drifts over time"}),(0,r.jsx)(n.td,{children:"Bounded error with loops"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:["For humanoid robots: ",(0,r.jsx)(n.strong,{children:"Use VSLAM"})," for long-term autonomy, VO for quick prototyping."]}),"\n",(0,r.jsx)(n.h2,{id:"isaac-ros-vslam-architecture",children:"Isaac ROS VSLAM Architecture"}),"\n",(0,r.jsx)(n.h3,{id:"system-components",children:"System Components"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Stereo Camera \u2192 Image Processing \u2192 Feature Detection \u2192 Visual Odometry\n                      \u2193                   \u2193                  \u2193\n                 GPU Accelerated     GPU Keypoints      Pose Graph\n                      \u2193                   \u2193                  \u2193\n                 Loop Closure \u2190 Map Management \u2190 Localization\n                      \u2193                   \u2193                  \u2193\n                 Optimized Map \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192 /map \u2192 /odom transform\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Key Isaac ROS Packages:"})}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"isaac_ros_visual_slam"}),": Core VSLAM implementation (cuVSLAM)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"isaac_ros_image_proc"}),": GPU-accelerated image preprocessing"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"isaac_ros_stereo_image_proc"}),": Stereo rectification and disparity"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"isaac_ros_dnn_inference"}),": Deep learning-based feature extraction"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"installation",children:"Installation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Install Isaac ROS prerequisites\nsudo apt-get install -y ros-humble-isaac-ros-visual-slam\n\n# Clone Isaac ROS common packages\ncd ~/ros2_ws/src\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_common.git\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_visual_slam.git\n\n# Build\ncd ~/ros2_ws\ncolcon build --packages-up-to isaac_ros_visual_slam\n\nsource install/setup.bash\n"})}),"\n",(0,r.jsx)(n.h2,{id:"setting-up-isaac-ros-vslam",children:"Setting Up Isaac ROS VSLAM"}),"\n",(0,r.jsx)(n.h3,{id:"hardware-requirements",children:"Hardware Requirements"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Minimum:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"NVIDIA Jetson Xavier NX / AGX Xavier / Orin"}),"\n",(0,r.jsx)(n.li,{children:"Stereo camera (ZED, RealSense D435i, or similar)"}),"\n",(0,r.jsx)(n.li,{children:"IMU (for sensor fusion)"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Recommended for Humanoids:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Jetson AGX Orin (best performance)"}),"\n",(0,r.jsx)(n.li,{children:"ZED 2i (built-in IMU, outdoor capable)"}),"\n",(0,r.jsx)(n.li,{children:"Head-mounted for stable viewpoint"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"camera-configuration",children:"Camera Configuration"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'# config/zed2i_stereo.yaml\n/**:\n  ros__parameters:\n    # Camera intrinsics (from calibration)\n    camera_info_url: "package://my_robot/config/zed2i_calibration.yaml"\n\n    # Image resolution (higher = more accurate but slower)\n    image_width: 1280\n    image_height: 720\n\n    # Frame rate (balance between smoothness and processing)\n    frame_rate: 30\n\n    # Stereo baseline (distance between cameras)\n    baseline: 0.12  # 12cm for ZED 2i\n'})}),"\n",(0,r.jsx)(n.h3,{id:"launch-file-for-vslam",children:"Launch File for VSLAM"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# launch/humanoid_vslam.launch.py\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\nfrom launch.actions import DeclareLaunchArgument\nfrom launch.substitutions import LaunchConfiguration\n\ndef generate_launch_description():\n    return LaunchDescription([\n        # Camera driver (ZED example)\n        Node(\n            package='zed_wrapper',\n            executable='zed_wrapper_node',\n            name='zed_node',\n            parameters=[{\n                'general.camera_model': 'zed2i',\n                'depth.depth_mode': 'ULTRA',\n                'pos_tracking.pos_tracking_enabled': False,  # Use Isaac ROS instead\n            }]\n        ),\n\n        # Isaac ROS Visual SLAM\n        Node(\n            package='isaac_ros_visual_slam',\n            executable='isaac_ros_visual_slam',\n            name='isaac_ros_visual_slam',\n            parameters=[{\n                'denoise_input_images': True,\n                'rectified_images': True,\n                'enable_image_denoising': True,\n                'enable_imu_fusion': True,\n                'gyro_noise_density': 0.000244,  # rad/s/\u221aHz\n                'gyro_random_walk': 0.000019,     # rad/s\xb2/\u221aHz\n                'accel_noise_density': 0.001862,  # m/s\xb2/\u221aHz\n                'accel_random_walk': 0.003,       # m/s\xb3/\u221aHz\n                'calibration_frequency': 200.0,   # Hz\n                'img_jitter_threshold_ms': 22.00,\n            }],\n            remappings=[\n                ('/stereo_camera/left/image', '/zed_node/left/image_rect_color'),\n                ('/stereo_camera/right/image', '/zed_node/right/image_rect_color'),\n                ('/stereo_camera/left/camera_info', '/zed_node/left/camera_info'),\n                ('/stereo_camera/right/camera_info', '/zed_node/right/camera_info'),\n                ('/visual_slam/imu', '/zed_node/imu/data'),\n            ]\n        ),\n\n        # Publish static TF for camera mount\n        Node(\n            package='tf2_ros',\n            executable='static_transform_publisher',\n            arguments=['0', '0', '1.7', '0', '0', '0', 'base_link', 'camera_link']\n        ),\n    ])\n"})}),"\n",(0,r.jsx)(n.h2,{id:"running-isaac-ros-vslam",children:"Running Isaac ROS VSLAM"}),"\n",(0,r.jsx)(n.h3,{id:"basic-usage",children:"Basic Usage"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Launch VSLAM\nros2 launch my_robot_description humanoid_vslam.launch.py\n\n# Visualize in RViz\nros2 run rviz2 rviz2 -d $(ros2 pkg prefix isaac_ros_visual_slam)/share/isaac_ros_visual_slam/rviz/default.rviz\n\n# Monitor performance\nros2 topic hz /visual_slam/tracking/odometry\nros2 topic echo /visual_slam/status\n"})}),"\n",(0,r.jsx)(n.h3,{id:"monitoring-vslam-status",children:"Monitoring VSLAM Status"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom isaac_ros_visual_slam_interfaces.msg import VisualSlamStatus\n\nclass VSLAMMonitor(Node):\n    def __init__(self):\n        super().__init__('vslam_monitor')\n\n        self.status_sub = self.create_subscription(\n            VisualSlamStatus,\n            '/visual_slam/status',\n            self.status_callback,\n            10\n        )\n\n    def status_callback(self, msg):\n        \"\"\"Monitor VSLAM health\"\"\"\n\n        # Check tracking status\n        if msg.vo_state == VisualSlamStatus.VO_STATE_LOST:\n            self.get_logger().error('VSLAM tracking LOST! Robot is blind.')\n        elif msg.vo_state == VisualSlamStatus.VO_STATE_INITIALIZING:\n            self.get_logger().warn('VSLAM initializing... Please move robot.')\n        elif msg.vo_state == VisualSlamStatus.VO_STATE_TRACKING:\n            self.get_logger().info(f'VSLAM tracking OK - {msg.num_observations} observations')\n\n        # Check loop closures\n        if msg.loop_closure_count > 0:\n            self.get_logger().info(f'Loop closure detected! Total: {msg.loop_closure_count}')\n\n        # Monitor feature count\n        if msg.num_observations < 50:\n            self.get_logger().warn(f'Low feature count: {msg.num_observations}. Add visual texture to environment.')\n\ndef main():\n    rclpy.init()\n    node = VSLAMMonitor()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,r.jsx)(n.h2,{id:"imu-sensor-fusion",children:"IMU Sensor Fusion"}),"\n",(0,r.jsx)(n.h3,{id:"why-fuse-imu-with-visual-data",children:"Why Fuse IMU with Visual Data?"}),"\n",(0,r.jsx)(n.p,{children:"Visual odometry alone fails during:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Fast rotation"}),": Motion blur makes feature tracking impossible"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Low texture"}),": Blank walls provide no visual features"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Occlusion"}),": Obstacles temporarily block camera view"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"IMU Benefits:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Provides orientation even when vision fails"}),"\n",(0,r.jsx)(n.li,{children:"Predicts motion between frames"}),"\n",(0,r.jsx)(n.li,{children:"Reduces drift in rotation estimates"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"imu-integration",children:"IMU Integration"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Imu\nfrom geometry_msgs.msg import PoseStamped\nimport numpy as np\n\nclass IMUPreprocessor(Node):\n    """Prepare IMU data for Isaac ROS VSLAM"""\n\n    def __init__(self):\n        super().__init__(\'imu_preprocessor\')\n\n        # Subscribe to raw IMU\n        self.imu_sub = self.create_subscription(\n            Imu,\n            \'/imu/data_raw\',\n            self.imu_callback,\n            10\n        )\n\n        # Publish processed IMU\n        self.imu_pub = self.create_publisher(Imu, \'/visual_slam/imu\', 10)\n\n        # Calibration offsets (determine experimentally)\n        self.gyro_bias = np.array([0.01, -0.02, 0.005])  # rad/s\n        self.accel_bias = np.array([0.0, 0.0, 9.81])     # m/s\xb2 (gravity)\n\n    def imu_callback(self, msg):\n        """Remove biases and republish"""\n\n        # Copy message\n        corrected = Imu()\n        corrected.header = msg.header\n        corrected.header.frame_id = \'imu_link\'\n\n        # Correct gyroscope bias\n        corrected.angular_velocity.x = msg.angular_velocity.x - self.gyro_bias[0]\n        corrected.angular_velocity.y = msg.angular_velocity.y - self.gyro_bias[1]\n        corrected.angular_velocity.z = msg.angular_velocity.z - self.gyro_bias[2]\n\n        # Correct accelerometer bias\n        corrected.linear_acceleration.x = msg.linear_acceleration.x - self.accel_bias[0]\n        corrected.linear_acceleration.y = msg.linear_acceleration.y - self.accel_bias[1]\n        corrected.linear_acceleration.z = msg.linear_acceleration.z - self.accel_bias[2]\n\n        # Copy orientation and covariances\n        corrected.orientation = msg.orientation\n        corrected.orientation_covariance = msg.orientation_covariance\n        corrected.angular_velocity_covariance = msg.angular_velocity_covariance\n        corrected.linear_acceleration_covariance = msg.linear_acceleration_covariance\n\n        self.imu_pub.publish(corrected)\n\ndef main():\n    rclpy.init()\n    node = IMUPreprocessor()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,r.jsx)(n.h2,{id:"map-management",children:"Map Management"}),"\n",(0,r.jsx)(n.h3,{id:"saving-and-loading-maps",children:"Saving and Loading Maps"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom isaac_ros_visual_slam_interfaces.srv import SaveMap, LoadMap\n\nclass MapManager(Node):\n    def __init__(self):\n        super().__init__('map_manager')\n\n        # Service clients\n        self.save_map_client = self.create_client(SaveMap, '/visual_slam/save_map')\n        self.load_map_client = self.create_client(LoadMap, '/visual_slam/load_map')\n\n    def save_current_map(self, map_folder_path):\n        \"\"\"Save the current VSLAM map\"\"\"\n\n        if not self.save_map_client.wait_for_service(timeout_sec=5.0):\n            self.get_logger().error('Save map service not available')\n            return False\n\n        request = SaveMap.Request()\n        request.map_folder_path = map_folder_path\n\n        future = self.save_map_client.call_async(request)\n        rclpy.spin_until_future_complete(self, future)\n\n        if future.result().success:\n            self.get_logger().info(f'Map saved to {map_folder_path}')\n            return True\n        else:\n            self.get_logger().error(f'Failed to save map: {future.result().message}')\n            return False\n\n    def load_existing_map(self, map_folder_path):\n        \"\"\"Load a previously saved map for localization\"\"\"\n\n        if not self.load_map_client.wait_for_service(timeout_sec=5.0):\n            self.get_logger().error('Load map service not available')\n            return False\n\n        request = LoadMap.Request()\n        request.map_folder_path = map_folder_path\n        request.localize_near_map = True  # Start localization immediately\n\n        future = self.load_map_client.call_async(request)\n        rclpy.spin_until_future_complete(self, future)\n\n        if future.result().success:\n            self.get_logger().info('Map loaded successfully')\n            return True\n        else:\n            self.get_logger().error(f'Failed to load map: {future.result().message}')\n            return False\n\n# Example usage\ndef main():\n    rclpy.init()\n    manager = MapManager()\n\n    # Save current map\n    manager.save_current_map('/home/robot/maps/office_floor1')\n\n    # Later: load map for localization-only mode\n    # manager.load_existing_map('/home/robot/maps/office_floor1')\n\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,r.jsx)(n.h2,{id:"integration-with-navigation-stack",children:"Integration with Navigation Stack"}),"\n",(0,r.jsx)(n.h3,{id:"publishing-odometry-for-nav2",children:"Publishing Odometry for Nav2"}),"\n",(0,r.jsx)(n.p,{children:"Isaac ROS VSLAM publishes odometry that Nav2 can use for navigation:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom nav_msgs.msg import Odometry\nfrom geometry_msgs.msg import TransformStamped\nimport tf2_ros\n\nclass OdometryBridge(Node):\n    \"\"\"Bridge VSLAM odometry to Nav2\"\"\"\n\n    def __init__(self):\n        super().__init__('odometry_bridge')\n\n        # Subscribe to VSLAM odometry\n        self.vslam_sub = self.create_subscription(\n            Odometry,\n            '/visual_slam/tracking/odometry',\n            self.vslam_callback,\n            10\n        )\n\n        # Publish to Nav2 expected topic\n        self.odom_pub = self.create_publisher(Odometry, '/odom', 10)\n\n        # TF broadcaster\n        self.tf_broadcaster = tf2_ros.TransformBroadcaster(self)\n\n    def vslam_callback(self, msg):\n        \"\"\"Relay VSLAM odometry to navigation stack\"\"\"\n\n        # Republish odometry\n        self.odom_pub.publish(msg)\n\n        # Broadcast TF transform\n        t = TransformStamped()\n        t.header.stamp = msg.header.stamp\n        t.header.frame_id = 'odom'\n        t.child_frame_id = 'base_link'\n\n        t.transform.translation.x = msg.pose.pose.position.x\n        t.transform.translation.y = msg.pose.pose.position.y\n        t.transform.translation.z = msg.pose.pose.position.z\n\n        t.transform.rotation = msg.pose.pose.orientation\n\n        self.tf_broadcaster.sendTransform(t)\n\ndef main():\n    rclpy.init()\n    node = OdometryBridge()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,r.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,r.jsx)(n.h3,{id:"gpu-memory-management",children:"GPU Memory Management"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# Optimize GPU memory for real-time performance\nexport CUDA_VISIBLE_DEVICES=0  # Use first GPU\nexport TF_FORCE_GPU_ALLOW_GROWTH=true  # Don't pre-allocate all memory\n"})}),"\n",(0,r.jsx)(n.h3,{id:"resolution-vs-speed-trade-off",children:"Resolution vs Speed Trade-off"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Resolution"}),(0,r.jsx)(n.th,{children:"FPS"}),(0,r.jsx)(n.th,{children:"Accuracy"}),(0,r.jsx)(n.th,{children:"Use Case"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"640x480"}),(0,r.jsx)(n.td,{children:"60+"}),(0,r.jsx)(n.td,{children:"Medium"}),(0,r.jsx)(n.td,{children:"Fast motion, indoor"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1280x720"}),(0,r.jsx)(n.td,{children:"30"}),(0,r.jsx)(n.td,{children:"High"}),(0,r.jsx)(n.td,{children:"General purpose"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1920x1080"}),(0,r.jsx)(n.td,{children:"15"}),(0,r.jsx)(n.td,{children:"Very High"}),(0,r.jsx)(n.td,{children:"Outdoor, large spaces"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"feature-count-tuning",children:"Feature Count Tuning"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"# config/vslam_performance.yaml\n/**:\n  ros__parameters:\n    # Reduce features for speed\n    num_features_per_frame: 200  # Default: 300\n\n    # Increase for accuracy in feature-rich environments\n    # num_features_per_frame: 500\n\n    # Map optimization frequency\n    enable_observations_view: false  # Disable visualization for speed\n    enable_landmarks_view: false\n    enable_localization_n_mapping: true\n"})}),"\n",(0,r.jsx)(n.h2,{id:"troubleshooting-common-issues",children:"Troubleshooting Common Issues"}),"\n",(0,r.jsx)(n.h3,{id:"problem-tracking-loss",children:"Problem: Tracking Loss"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Symptoms:"}),' Robot reports "VO_STATE_LOST"']}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Causes & Solutions:"})}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Low texture environment"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Add visual markers (AprilTags, posters)"}),"\n",(0,r.jsx)(n.li,{children:"Increase camera exposure"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Motion too fast"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Reduce walking speed during turns"}),"\n",(0,r.jsx)(n.li,{children:"Increase camera frame rate"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Lighting changes"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Enable auto-exposure"}),"\n",(0,r.jsx)(n.li,{children:"Use HDR camera mode"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"problem-high-drift",children:"Problem: High Drift"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Symptoms:"})," Robot returns to start but map doesn't align"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Solutions:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Enable loop closure detection"}),"\n",(0,r.jsx)(n.li,{children:"Improve IMU calibration"}),"\n",(0,r.jsx)(n.li,{children:"Add more loop closures by revisiting areas"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"problem-slow-performance",children:"Problem: Slow Performance"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Check:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Monitor GPU usage\nnvidia-smi -l 1\n\n# Check if GPU acceleration is active\nros2 param get /isaac_ros_visual_slam use_gpu\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Solutions:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Reduce image resolution"}),"\n",(0,r.jsx)(n.li,{children:"Lower feature count"}),"\n",(0,r.jsx)(n.li,{children:"Disable map visualization"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,r.jsx)(n.p,{children:"Isaac ROS VSLAM enables humanoid robots to navigate autonomously using vision:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Key Capabilities:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Real-time visual localization and mapping"}),"\n",(0,r.jsx)(n.li,{children:"GPU-accelerated for sub-10ms latency"}),"\n",(0,r.jsx)(n.li,{children:"IMU fusion for robust tracking"}),"\n",(0,r.jsx)(n.li,{children:"Loop closure for drift correction"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Best Practices:"})}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Mount camera at head height for stable viewpoint"}),"\n",(0,r.jsx)(n.li,{children:"Fuse IMU data for better performance"}),"\n",(0,r.jsx)(n.li,{children:"Save maps for faster relocalization"}),"\n",(0,r.jsx)(n.li,{children:"Tune parameters based on environment"}),"\n",(0,r.jsx)(n.li,{children:"Monitor tracking status continuously"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Integration Points:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Publishes ",(0,r.jsx)(n.code,{children:"/odom"})," \u2192 ",(0,r.jsx)(n.code,{children:"/base_link"})," transform for Nav2"]}),"\n",(0,r.jsxs)(n.li,{children:["Provides ",(0,r.jsx)(n.code,{children:"/map"})," frame for global localization"]}),"\n",(0,r.jsx)(n.li,{children:"Supports save/load for multi-session operation"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"With Isaac ROS VSLAM, humanoid robots can navigate complex indoor and outdoor environments without external infrastructure like GPS or motion capture systems."})]})}function m(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>o,x:()=>l});var s=a(6540);const r={},i=s.createContext(r);function o(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);