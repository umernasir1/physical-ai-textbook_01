"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[9636],{8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>s});var r=i(6540);const a={},t=r.createContext(a);function o(n){const e=r.useContext(t);return r.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:o(n.components),r.createElement(t.Provider,{value:e},n.children)}},9883:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>o,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"module3-ai-robot-brain/nvidia-isaac-sim","title":"NVIDIA Isaac Sim","description":"Introduction to Photorealistic Robot Simulation","source":"@site/docs/module3-ai-robot-brain/nvidia-isaac-sim.md","sourceDirName":"module3-ai-robot-brain","slug":"/module3-ai-robot-brain/nvidia-isaac-sim","permalink":"/physical-ai-textbook_01/docs/module3-ai-robot-brain/nvidia-isaac-sim","draft":false,"unlisted":false,"editUrl":"https://github.com/umernasir1/physical-ai-textbook/tree/main/docs/module3-ai-robot-brain/nvidia-isaac-sim.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"NVIDIA Isaac Sim"},"sidebar":"tutorialSidebar","previous":{"title":"Advanced Perception and Training","permalink":"/physical-ai-textbook_01/docs/module3-ai-robot-brain/advanced-perception-training"},"next":{"title":"Isaac ROS (Hardware-accelerated VSLAM and Navigation)","permalink":"/physical-ai-textbook_01/docs/module3-ai-robot-brain/isaac-ros-vslam-navigation"}}');var a=i(4848),t=i(8453);const o={sidebar_position:2,title:"NVIDIA Isaac Sim"},s="NVIDIA Isaac Sim",l={},c=[{value:"Introduction to Photorealistic Robot Simulation",id:"introduction-to-photorealistic-robot-simulation",level:2},{value:"Getting Started with Isaac Sim",id:"getting-started-with-isaac-sim",level:2},{value:"System Requirements",id:"system-requirements",level:3},{value:"Installation",id:"installation",level:3},{value:"First Simulation: Hello World",id:"first-simulation-hello-world",level:3},{value:"Understanding the Isaac Sim Architecture",id:"understanding-the-isaac-sim-architecture",level:2},{value:"USD (Universal Scene Description)",id:"usd-universal-scene-description",level:3},{value:"Physics Simulation with PhysX 5",id:"physics-simulation-with-physx-5",level:3},{value:"Loading and Simulating Robots",id:"loading-and-simulating-robots",level:2},{value:"Importing Robot Models",id:"importing-robot-models",level:3},{value:"Articulation Controller",id:"articulation-controller",level:3},{value:"Sensor Simulation",id:"sensor-simulation",level:2},{value:"RGB Camera",id:"rgb-camera",level:3},{value:"Depth Camera",id:"depth-camera",level:3},{value:"LiDAR Simulation",id:"lidar-simulation",level:3},{value:"IMU (Inertial Measurement Unit)",id:"imu-inertial-measurement-unit",level:3},{value:"Environment Building",id:"environment-building",level:2},{value:"Creating a Warehouse Scene",id:"creating-a-warehouse-scene",level:3},{value:"Randomized Environments for Training",id:"randomized-environments-for-training",level:3},{value:"Integration with ROS 2",id:"integration-with-ros-2",level:2},{value:"Reinforcement Learning with Isaac Sim",id:"reinforcement-learning-with-isaac-sim",level:2},{value:"Best Practices for Isaac Sim",id:"best-practices-for-isaac-sim",level:2},{value:"Conclusion",id:"conclusion",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"nvidia-isaac-sim",children:"NVIDIA Isaac Sim"})}),"\n",(0,a.jsx)(e.h2,{id:"introduction-to-photorealistic-robot-simulation",children:"Introduction to Photorealistic Robot Simulation"}),"\n",(0,a.jsx)(e.p,{children:"NVIDIA Isaac Sim is a revolutionary robot simulation platform built on NVIDIA Omniverse. Unlike traditional simulators (Gazebo, PyBullet), Isaac Sim provides photorealistic rendering, physically accurate simulations, and seamless integration with AI training workflows\u2014all running on RTX GPUs for real-time performance."}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Why Isaac Sim is Different:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Ray-Traced Rendering"}),": Photorealistic lighting, reflections, and shadows using RTX technology"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"PhysX 5 Engine"}),": Highly accurate rigid body dynamics, soft body physics, and collision detection"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"USD Foundation"}),": Universal Scene Description (USD) enables asset sharing across film, gaming, and robotics"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"AI-Ready"}),": Native integration with synthetic data generation and reinforcement learning"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"ROS 2 Bridge"}),": Seamless connection to ROS 2 ecosystem for real robot deployment"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"getting-started-with-isaac-sim",children:"Getting Started with Isaac Sim"}),"\n",(0,a.jsx)(e.h3,{id:"system-requirements",children:"System Requirements"}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Minimum Specifications:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"GPU: NVIDIA RTX 2070 or higher (8GB VRAM)"}),"\n",(0,a.jsx)(e.li,{children:"CPU: Intel Core i7 or AMD Ryzen 7"}),"\n",(0,a.jsx)(e.li,{children:"RAM: 32GB"}),"\n",(0,a.jsx)(e.li,{children:"OS: Ubuntu 20.04/22.04 or Windows 10/11"}),"\n",(0,a.jsx)(e.li,{children:"Storage: 50GB SSD space"}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Recommended Specifications:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"GPU: NVIDIA RTX 4080 or higher (12GB+ VRAM)"}),"\n",(0,a.jsx)(e.li,{children:"CPU: Intel Core i9 13th Gen or AMD Ryzen 9"}),"\n",(0,a.jsx)(e.li,{children:"RAM: 64GB DDR5"}),"\n",(0,a.jsx)(e.li,{children:"OS: Ubuntu 22.04 LTS (native ROS 2 support)"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"installation",children:"Installation"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"# Download and install Omniverse Launcher\n# Visit: https://www.nvidia.com/en-us/omniverse/download/\n\n# Install Isaac Sim from Omniverse Launcher (select latest version)\n# Typical path: ~/.local/share/ov/pkg/isaac_sim-2023.1.1\n\n# Set environment variables\necho 'export ISAAC_SIM_PATH=\"$HOME/.local/share/ov/pkg/isaac_sim-2023.1.1\"' >> ~/.bashrc\necho 'export PYTHONPATH=\"${ISAAC_SIM_PATH}/exts/omni.isaac.python_app/pip_prebundle:${PYTHONPATH}\"' >> ~/.bashrc\nsource ~/.bashrc\n\n# Verify installation\ncd $ISAAC_SIM_PATH\n./isaac-sim.sh\n"})}),"\n",(0,a.jsx)(e.h3,{id:"first-simulation-hello-world",children:"First Simulation: Hello World"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# hello_isaac.py\nfrom omni.isaac.kit import SimulationApp\n\n# Launch Isaac Sim\nsimulation_app = SimulationApp({"headless": False})\n\nfrom omni.isaac.core import World\nfrom omni.isaac.core.objects import DynamicCuboid\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\n\n# Create simulation world\nworld = World()\n\n# Add ground plane\nworld.scene.add_default_ground_plane()\n\n# Add a dynamic cube\ncube = DynamicCuboid(\n    prim_path="/World/Cube",\n    name="my_cube",\n    position=[0, 0, 1.0],  # 1 meter above ground\n    size=0.2,  # 20cm cube\n    color=[1.0, 0.0, 0.0]  # Red\n)\n\nworld.scene.add(cube)\n\n# Reset simulation\nworld.reset()\n\n# Run simulation for 1000 steps\nfor i in range(1000):\n    world.step(render=True)\n\n# Cleanup\nsimulation_app.close()\n'})}),"\n",(0,a.jsx)(e.p,{children:"Run the script:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",children:"cd $ISAAC_SIM_PATH\n./python.sh /path/to/hello_isaac.py\n"})}),"\n",(0,a.jsx)(e.h2,{id:"understanding-the-isaac-sim-architecture",children:"Understanding the Isaac Sim Architecture"}),"\n",(0,a.jsx)(e.h3,{id:"usd-universal-scene-description",children:"USD (Universal Scene Description)"}),"\n",(0,a.jsx)(e.p,{children:"Isaac Sim uses USD as its foundation\u2014a file format developed by Pixar for complex 3D scenes."}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Key USD Concepts:"})}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Prims (Primitives)"}),": Basic building blocks of a scene (meshes, lights, cameras)"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Properties"}),": Attributes of prims (position, rotation, color)"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Hierarchy"}),": Prims organized in a tree structure (like a file system)"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Layers"}),": Non-destructive editing through layer composition"]}),"\n"]}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'from pxr import Usd, UsdGeom, Gf\n\n# Access the USD stage\nstage = omni.usd.get_context().get_stage()\n\n# Create a sphere prim\nsphere_path = "/World/Sphere"\nsphere_geom = UsdGeom.Sphere.Define(stage, sphere_path)\n\n# Set properties\nsphere_geom.GetRadiusAttr().Set(0.5)\nsphere_geom.AddTranslateOp().Set(Gf.Vec3f(1.0, 0.0, 0.5))\n\n# Set color (requires material binding in practice)\ncolor_attr = sphere_geom.GetDisplayColorAttr()\ncolor_attr.Set([(0.0, 1.0, 0.0)])  # Green\n'})}),"\n",(0,a.jsx)(e.h3,{id:"physics-simulation-with-physx-5",children:"Physics Simulation with PhysX 5"}),"\n",(0,a.jsx)(e.p,{children:"Isaac Sim integrates NVIDIA PhysX 5 for realistic physics:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"from omni.isaac.core.prims import RigidPrimView\nfrom omni.isaac.core.utils.physics import simulate_async\n\n# Create a rigid body with physics\nfrom pxr import UsdPhysics, PhysxSchema\n\n# Define rigid body\nrigid_body = UsdPhysics.RigidBodyAPI.Apply(sphere_geom.GetPrim())\n\n# Add collision shape\ncollision_api = UsdPhysics.CollisionAPI.Apply(sphere_geom.GetPrim())\n\n# Set physics properties\nmass_api = UsdPhysics.MassAPI.Apply(sphere_geom.GetPrim())\nmass_api.GetMassAttr().Set(1.0)  # 1 kg\n\n# Set friction and restitution\nmaterial = UsdPhysics.MaterialAPI.Apply(sphere_geom.GetPrim())\nmaterial.CreateStaticFrictionAttr().Set(0.5)\nmaterial.CreateDynamicFrictionAttr().Set(0.4)\nmaterial.CreateRestitutionAttr().Set(0.6)  # Bounciness\n"})}),"\n",(0,a.jsx)(e.h2,{id:"loading-and-simulating-robots",children:"Loading and Simulating Robots"}),"\n",(0,a.jsx)(e.h3,{id:"importing-robot-models",children:"Importing Robot Models"}),"\n",(0,a.jsx)(e.p,{children:"Isaac Sim supports multiple robot formats:"}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"1. URDF Import:"})}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'from omni.isaac.urdf import _urdf\n\n# Import URDF (converted to USD internally)\nurdf_path = "/path/to/robot.urdf"\nusd_path = "/World/Robot"\n\n# Import configuration\nimport_config = _urdf.ImportConfig()\nimport_config.merge_fixed_joints = False\nimport_config.convex_decomp = True  # For collision meshes\nimport_config.import_inertia_tensor = True\nimport_config.fix_base = False  # True for fixed-base robots\n\n# Import robot\nsuccess, prim_path = omni.kit.commands.execute(\n    "URDFParseAndImportFile",\n    urdf_path=urdf_path,\n    import_config=import_config,\n    dest_path=usd_path\n)\n'})}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"2. Loading Pre-built Assets:"})}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'from omni.isaac.core.utils.stage import add_reference_to_stage\n\n# Load from Isaac Sim asset library\nrobot_asset = "omniverse://localhost/NVIDIA/Assets/Isaac/2023.1.1/Isaac/Robots/Unitree/G1/g1.usd"\n\nadd_reference_to_stage(\n    usd_path=robot_asset,\n    prim_path="/World/Humanoid"\n)\n'})}),"\n",(0,a.jsx)(e.h3,{id:"articulation-controller",children:"Articulation Controller"}),"\n",(0,a.jsx)(e.p,{children:"Control robot joints using the Articulation API:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'from omni.isaac.core.articulations import Articulation\nfrom omni.isaac.core.utils.types import ArticulationAction\n\n# Create articulation controller\nrobot = Articulation(prim_path="/World/Humanoid")\nrobot.initialize()\n\n# Get joint information\njoint_names = robot.dof_names\nnum_dof = robot.num_dof\nprint(f"Robot has {num_dof} degrees of freedom: {joint_names}")\n\n# Set joint positions (position control)\ntarget_positions = [0.0] * num_dof  # All joints to 0\ntarget_positions[0] = 0.5  # First joint to 0.5 radians\n\naction = ArticulationAction(joint_positions=target_positions)\nrobot.apply_action(action)\n\n# Set joint velocities (velocity control)\ntarget_velocities = [0.0] * num_dof\ntarget_velocities[1] = 1.0  # Second joint at 1 rad/s\n\naction = ArticulationAction(joint_velocities=target_velocities)\nrobot.apply_action(action)\n\n# Set joint efforts (torque control)\ntarget_efforts = [0.0] * num_dof\ntarget_efforts[2] = 10.0  # Apply 10 Nm torque to third joint\n\naction = ArticulationAction(joint_efforts=target_efforts)\nrobot.apply_action(action)\n'})}),"\n",(0,a.jsx)(e.h2,{id:"sensor-simulation",children:"Sensor Simulation"}),"\n",(0,a.jsx)(e.p,{children:"Isaac Sim provides accurate sensor models essential for perception testing."}),"\n",(0,a.jsx)(e.h3,{id:"rgb-camera",children:"RGB Camera"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'from omni.isaac.sensor import Camera\nimport numpy as np\n\n# Create RGB camera\ncamera = Camera(\n    prim_path="/World/Camera",\n    position=np.array([2.0, 2.0, 1.5]),\n    frequency=30,  # 30 Hz\n    resolution=(1280, 720),\n    orientation=np.array([0.0, 0.0, 0.0, 1.0])  # Quaternion\n)\n\n# Initialize camera\ncamera.initialize()\n\n# Capture frame\ncamera.add_distance_to_camera_to_frame()\nframe_data = camera.get_current_frame()\n\nrgb_image = frame_data["rgba"][:, :, :3]  # Remove alpha channel\nprint(f"Captured image shape: {rgb_image.shape}")\n'})}),"\n",(0,a.jsx)(e.h3,{id:"depth-camera",children:"Depth Camera"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# Enable depth output\ncamera.add_depth_to_frame()\n\n# Capture depth\nframe_data = camera.get_current_frame()\ndepth_image = frame_data["depth"]\n\n# Depth is in meters\nprint(f"Min depth: {depth_image.min()}, Max depth: {depth_image.max()}")\n'})}),"\n",(0,a.jsx)(e.h3,{id:"lidar-simulation",children:"LiDAR Simulation"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'from omni.isaac.range_sensor import _range_sensor\n\n# Create LiDAR sensor\nlidar_config = _range_sensor.LidarSensorConfig()\nlidar_config.min_range = 0.1  # meters\nlidar_config.max_range = 100.0\nlidar_config.horizontal_fov = 360.0  # degrees\nlidar_config.vertical_fov = 30.0\nlidar_config.horizontal_resolution = 0.4  # degrees\nlidar_config.vertical_resolution = 1.0\nlidar_config.rotation_rate = 20.0  # Hz\n\n# Create LiDAR\nresult, lidar = omni.kit.commands.execute(\n    "RangeSensorCreateLidar",\n    path="/World/Lidar",\n    parent="/World/Robot",\n    config=lidar_config,\n    translation=(0, 0, 0.5)\n)\n\n# Read LiDAR data\nlidar_interface = _range_sensor.acquire_lidar_sensor_interface()\ndepth_data = lidar_interface.get_linear_depth_data("/World/Lidar")\nazimuth_data = lidar_interface.get_azimuth_data("/World/Lidar")\nelevation_data = lidar_interface.get_elevation_data("/World/Lidar")\n'})}),"\n",(0,a.jsx)(e.h3,{id:"imu-inertial-measurement-unit",children:"IMU (Inertial Measurement Unit)"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'from omni.isaac.sensor import IMUSensor\n\n# Create IMU\nimu = IMUSensor(\n    prim_path="/World/Robot/IMU",\n    translation=np.array([0, 0, 0.1]),  # Mounted on robot\n    frequency=100  # 100 Hz\n)\n\nimu.initialize()\n\n# Read IMU data\nimu_reading = imu.get_current_frame()\n\nlinear_acceleration = imu_reading["lin_acc"]  # m/s^2\nangular_velocity = imu_reading["ang_vel"]  # rad/s\norientation = imu_reading["orientation"]  # Quaternion\n\nprint(f"Acceleration: {linear_acceleration}")\nprint(f"Angular velocity: {angular_velocity}")\n'})}),"\n",(0,a.jsx)(e.h2,{id:"environment-building",children:"Environment Building"}),"\n",(0,a.jsx)(e.h3,{id:"creating-a-warehouse-scene",children:"Creating a Warehouse Scene"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'from omni.isaac.core import World\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom omni.isaac.core.utils.prims import create_prim\n\nworld = World()\n\n# Add warehouse floor\nfloor_prim = create_prim(\n    prim_path="/World/Floor",\n    prim_type="Cube",\n    position=[0, 0, -0.05],\n    scale=[20, 20, 0.1],\n    semantic_label="floor"\n)\n\n# Add shelves (repeated)\nfor i in range(5):\n    shelf_path = f"/World/Shelf_{i}"\n    add_reference_to_stage(\n        usd_path="omniverse://localhost/NVIDIA/Assets/Industrial/Shelves/shelf_unit.usd",\n        prim_path=shelf_path\n    )\n    # Position shelves\n    create_prim(shelf_path).GetAttribute("xformOp:translate").Set((i * 2.0, 0, 0))\n\n# Add boxes on shelves\nfor i in range(20):\n    box = DynamicCuboid(\n        prim_path=f"/World/Box_{i}",\n        position=[\n            np.random.uniform(-5, 5),\n            np.random.uniform(-5, 5),\n            np.random.uniform(0.5, 2.0)\n        ],\n        size=0.2,\n        color=np.random.rand(3)\n    )\n    world.scene.add(box)\n\n# Add lighting\nfrom pxr import UsdLux\ndome_light = UsdLux.DomeLight.Define(world.stage, "/World/DomeLight")\ndome_light.CreateIntensityAttr(1000.0)\n'})}),"\n",(0,a.jsx)(e.h3,{id:"randomized-environments-for-training",children:"Randomized Environments for Training"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'import random\n\nclass EnvironmentRandomizer:\n    """Randomize environments for robust AI training"""\n    def __init__(self, world):\n        self.world = world\n\n    def randomize_lighting(self):\n        """Randomize scene lighting"""\n        stage = self.world.stage\n        dome_light = UsdLux.DomeLight.Get(stage, "/World/DomeLight")\n\n        # Random intensity\n        intensity = random.uniform(500, 2000)\n        dome_light.GetIntensityAttr().Set(intensity)\n\n        # Random color temperature\n        temperature = random.uniform(3000, 7000)\n        dome_light.GetColorTemperatureAttr().Set(temperature)\n\n    def randomize_object_poses(self):\n        """Randomize object positions"""\n        for i in range(20):\n            box_path = f"/World/Box_{i}"\n            prim = self.world.stage.GetPrimAtPath(box_path)\n\n            new_position = (\n                random.uniform(-5, 5),\n                random.uniform(-5, 5),\n                random.uniform(0.5, 2.0)\n            )\n\n            prim.GetAttribute("xformOp:translate").Set(new_position)\n\n    def randomize_materials(self):\n        """Randomize object materials and textures"""\n        from omni.isaac.core.materials import PreviewSurface\n\n        for i in range(20):\n            box_path = f"/World/Box_{i}"\n            material = PreviewSurface(prim_path=f"{box_path}/Material")\n\n            # Random color\n            color = (random.random(), random.random(), random.random())\n            material.set_color(color)\n\n            # Random metallic/roughness\n            material.set_metallic(random.uniform(0, 1))\n            material.set_roughness(random.uniform(0, 1))\n'})}),"\n",(0,a.jsx)(e.h2,{id:"integration-with-ros-2",children:"Integration with ROS 2"}),"\n",(0,a.jsx)(e.p,{children:"Isaac Sim provides a native ROS 2 bridge for seamless integration:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# Enable ROS 2 bridge\nimport omni.isaac.ros2_bridge as ros2_bridge\n\n# Start ROS 2 bridge\nros2_bridge.enable_ros2()\n\n# Publish camera data to ROS 2\ncamera_helper = ros2_bridge.create_camera_publisher(\n    camera_prim_path="/World/Camera",\n    topic_name="/camera/image_raw",\n    message_type="sensor_msgs/Image",\n    publish_rate=30\n)\n\n# Publish LiDAR data\nlidar_helper = ros2_bridge.create_lidar_publisher(\n    lidar_prim_path="/World/Lidar",\n    topic_name="/scan",\n    message_type="sensor_msgs/LaserScan"\n)\n\n# Subscribe to velocity commands\ndef cmd_vel_callback(linear_x, linear_y, angular_z):\n    # Apply velocities to robot\n    robot.set_linear_velocity([linear_x, linear_y, 0])\n    robot.set_angular_velocity([0, 0, angular_z])\n\ncmd_vel_sub = ros2_bridge.create_subscriber(\n    topic_name="/cmd_vel",\n    message_type="geometry_msgs/Twist",\n    callback=cmd_vel_callback\n)\n'})}),"\n",(0,a.jsx)(e.h2,{id:"reinforcement-learning-with-isaac-sim",children:"Reinforcement Learning with Isaac Sim"}),"\n",(0,a.jsx)(e.p,{children:"Train humanoid control policies using RL:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'from omni.isaac.gym.vec_env import VecEnvBase\nimport torch\n\nclass HumanoidWalkEnv(VecEnvBase):\n    """Custom RL environment for humanoid walking"""\n    def __init__(self, num_envs=4096):\n        self.num_envs = num_envs\n        super().__init__(num_envs=num_envs)\n\n    def get_observations(self):\n        """Return current observations"""\n        # Joint positions, velocities\n        joint_pos = self.robot.get_joint_positions()\n        joint_vel = self.robot.get_joint_velocities()\n\n        # Base orientation (from IMU)\n        base_orientation = self.imu.get_current_frame()["orientation"]\n\n        obs = torch.cat([joint_pos, joint_vel, base_orientation], dim=-1)\n        return obs\n\n    def calculate_reward(self):\n        """Compute reward signal"""\n        # Reward for forward movement\n        velocity = self.robot.get_linear_velocity()\n        forward_reward = velocity[0]\n\n        # Penalty for falling\n        height = self.robot.get_world_pose()[0][2]\n        fall_penalty = -10.0 if height < 0.3 else 0.0\n\n        # Penalty for high energy consumption\n        joint_efforts = self.robot.get_measured_joint_efforts()\n        energy_penalty = -0.001 * torch.sum(torch.abs(joint_efforts))\n\n        return forward_reward + fall_penalty + energy_penalty\n\n    def step(self, actions):\n        """Execute actions and return results"""\n        # Apply actions (joint targets)\n        self.robot.apply_action(ArticulationAction(joint_positions=actions))\n\n        # Simulate\n        self.world.step()\n\n        # Get observations\n        obs = self.get_observations()\n\n        # Calculate rewards\n        rewards = self.calculate_reward()\n\n        # Check for episode termination\n        dones = self.robot.get_world_pose()[0][:, 2] < 0.2  # Fallen\n\n        return obs, rewards, dones, {}\n'})}),"\n",(0,a.jsx)(e.h2,{id:"best-practices-for-isaac-sim",children:"Best Practices for Isaac Sim"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Performance Optimization"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Use headless mode for batch data generation"}),"\n",(0,a.jsx)(e.li,{children:"Reduce scene complexity when possible"}),"\n",(0,a.jsx)(e.li,{children:"Enable GPU acceleration for physics"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Asset Management"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Use USD references instead of duplicating assets"}),"\n",(0,a.jsx)(e.li,{children:"Organize scenes with clear hierarchy"}),"\n",(0,a.jsx)(e.li,{children:"Leverage Omniverse Nucleus for team collaboration"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Debugging"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Use visual debugger for physics issues"}),"\n",(0,a.jsx)(e.li,{children:"Enable collision visualization"}),"\n",(0,a.jsx)(e.li,{children:"Log joint states and sensor data"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Sim-to-Real"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Add realistic sensor noise"}),"\n",(0,a.jsx)(e.li,{children:"Implement domain randomization"}),"\n",(0,a.jsx)(e.li,{children:"Validate with real-world data early"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,a.jsx)(e.p,{children:"NVIDIA Isaac Sim transforms robot development by providing:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Photorealistic simulation for accurate perception training"}),"\n",(0,a.jsx)(e.li,{children:"Hardware-accelerated physics for real-time performance"}),"\n",(0,a.jsx)(e.li,{children:"Seamless ROS 2 integration for deployment"}),"\n",(0,a.jsx)(e.li,{children:"Native support for reinforcement learning workflows"}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Next"}),": We'll explore Isaac ROS\u2014hardware-accelerated perception pipelines for VSLAM and navigation on Jetson devices."]}),"\n",(0,a.jsx)(e.hr,{}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Key Takeaways:"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Isaac Sim provides photorealistic rendering and accurate physics simulation"}),"\n",(0,a.jsx)(e.li,{children:"USD enables powerful asset management and scene composition"}),"\n",(0,a.jsx)(e.li,{children:"Sensor simulation (cameras, LiDAR, IMU) generates realistic training data"}),"\n",(0,a.jsx)(e.li,{children:"ROS 2 bridge enables seamless integration with robot software stacks"}),"\n",(0,a.jsx)(e.li,{children:"Built-in RL support accelerates policy training for locomotion and manipulation"}),"\n"]})]})}function m(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(d,{...n})}):d(n)}}}]);